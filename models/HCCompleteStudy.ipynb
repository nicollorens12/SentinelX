{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchy Classificator Complete Study\n",
    "\n",
    "With all the information gathered with `HierarchyClassificatorLevelStudy.ipynb` we've created the 3 layer model called `HerarchyModel.py` that takes 3 trained models and uses this herarchy structure to predict different attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorflow as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nico\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "Installing collected packages: tensorflow-intel, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Nico\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\tensorflow\\\\include\\\\external\\\\com_github_grpc_grpc\\\\src\\\\core\\\\ext\\\\filters\\\\client_channel\\\\lb_policy\\\\grpclb\\\\client_load_reporting_filter.h'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\Nico\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas\n",
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install scikit-learn\n",
    "#!pip install fastparquet\n",
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow\n",
    "#!pip install keras\n",
    "#!pip uninstall xgboost\n",
    "#!pip install xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from models.HerarchyModel.HierarchyModel import HerarchyModel\n",
    "\n",
    "from fastparquet import ParquetFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('Datasets/Complete/cic-collection.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "BruteForce      2020\n",
      "XSS              876\n",
      "SQLInjection      99\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.columns = data.columns.str.strip()\n",
    "data.rename(columns={'Label': 'AttackType'}, inplace=True)\n",
    "\n",
    "data = data[data['AttackType'].str.contains('Webattack-Bruteforce|Webattack-XSS|Webattack-SQLi', case=False)]\n",
    "\n",
    "\n",
    "data['AttackType'] = data['AttackType'].str.replace('Webattack-bruteforce', 'BruteForce', case=False)\n",
    "data['AttackType'] = data['AttackType'].str.replace('Webattack-XSS', 'XSS', case=False)\n",
    "data['AttackType'] = data['AttackType'].str.replace('Webattack-SQLi', 'SQLInjection', case=False)\n",
    "\n",
    "print(data['AttackType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "BENIGN                        393441\n",
      "PortScan                      158930\n",
      "DDoS                          128027\n",
      "Web Attack - Brute Force        1507\n",
      "Web Attack - XSS                 652\n",
      "Web Attack - Sql Injection        21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataDdos = pd.read_csv('Datasets/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "dataPortScan = pd.read_csv('Datasets/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
    "dataWebAttacks = pd.read_csv('Datasets/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
    "\n",
    "dataSmall = pd.concat([dataDdos, dataPortScan, dataWebAttacks], ignore_index=True)\n",
    "\n",
    "dataSmall.columns = dataSmall.columns.str.strip()\n",
    "\n",
    "dataSmall.rename(columns={'Label': 'AttackType'}, inplace=True)\n",
    "dataSmall['AttackType'] = dataSmall['AttackType'].str.replace('�', '-')\n",
    "\n",
    "print(dataSmall['AttackType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "BENIGN          393441\n",
      "PortScan        158930\n",
      "DDoS            128027\n",
      "BruteForce        1507\n",
      "XSS                652\n",
      "SQLInjection        21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataSmall['AttackType'] = dataSmall['AttackType'].str.replace('Web Attack - Brute Force', 'BruteForce')\n",
    "dataSmall['AttackType'] = dataSmall['AttackType'].str.replace('Web Attack - XSS', 'XSS')\n",
    "dataSmall['AttackType'] = dataSmall['AttackType'].str.replace('Web Attack - Sql Injection', 'SQLInjection')\n",
    "print(dataSmall['AttackType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataSmall and data do not have the same columns.\n",
      "Columns in data but not in dataSmall: {'Avg Packet Size', 'Fwd Packets Length Total', 'Fwd Act Data Packets', 'Init Fwd Win Bytes', 'ClassLabel', 'Bwd Packets Length Total', 'Packet Length Max', 'Init Bwd Win Bytes', 'Fwd Seg Size Min'}\n",
      "Columns in dataSmall but not in data: {'FIN Flag Count', 'Min Packet Length', 'min_seg_size_forward', 'Bwd PSH Flags', 'Bwd Avg Packets/Bulk', 'Init_Win_bytes_forward', 'act_data_pkt_fwd', 'Down/Up Ratio', 'Max Packet Length', 'ACK Flag Count', 'ECE Flag Count', 'Total Length of Bwd Packets', 'Bwd URG Flags', 'Total Length of Fwd Packets', 'Bwd Avg Bulk Rate', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Fwd Avg Bytes/Bulk', 'Fwd Packet Length Min', 'Init_Win_bytes_backward', 'Fwd Header Length.1', 'Average Packet Size', 'CWE Flag Count', 'PSH Flag Count', 'Bwd Packet Length Min', 'Bwd Avg Bytes/Bulk', 'Fwd URG Flags', 'Destination Port', 'RST Flag Count'}\n",
      "Number of columns they share: 50\n"
     ]
    }
   ],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "dataSmall.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataSmall.dropna(inplace=True)\n",
    "\n",
    "# Check if dataSmall and data have the same columns\n",
    "columns_data = set(data.columns)\n",
    "columns_dataSmall = set(dataSmall.columns)\n",
    "\n",
    "if columns_data == columns_dataSmall:\n",
    "    print(\"dataSmall and data have the same columns.\")\n",
    "else:\n",
    "    print(\"dataSmall and data do not have the same columns.\")\n",
    "    print(\"Columns in data but not in dataSmall:\", columns_data - columns_dataSmall)\n",
    "    print(\"Columns in dataSmall but not in data:\", columns_dataSmall - columns_data)\n",
    "    \n",
    "    shared_columns = columns_data.intersection(columns_dataSmall)\n",
    "    print(f\"Number of columns they share: {len(shared_columns)}\")\n",
    "\n",
    "shared_columns = list(shared_columns)\n",
    "data = data[shared_columns]\n",
    "dataSmall = dataSmall[shared_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685033, 50)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([data, dataSmall], ignore_index=True)\n",
    "\n",
    "dataset.to_csv('Datasets/Complete/Dataset.csv', index=False)\n",
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We will retrain the models again, this time with the complete Datset, so we don't have any inconsistencies. We will be taking the parameters that performed best in each layer study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1 - Random Forest\n",
    "\n",
    "MALIGN - BENIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('AttackType', axis=1)\n",
    "y = dataset['AttackType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "BENIGN          393029\n",
      "PortScan        158804\n",
      "DDoS            128025\n",
      "BruteForce       50000\n",
      "XSS              50000\n",
      "SQLInjection     50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_classes = {\n",
    "    \"BruteForce\": 50000,\n",
    "    \"XSS\": 50000,\n",
    "    \"SQLInjection\": 50000\n",
    "}\n",
    "\n",
    "smote = SMOTE(sampling_strategy=target_classes, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "MALIGN    436829\n",
      "BENIGN    393029\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_resampled = y_resampled.apply(lambda x: 'MALIGN' if x != 'BENIGN' else x)\n",
    "print(y_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       0.99      1.00      1.00     78452\n",
      "      MALIGN       1.00      1.00      1.00     87520\n",
      "\n",
      "    accuracy                           1.00    165972\n",
      "   macro avg       1.00      1.00      1.00    165972\n",
      "weighted avg       1.00      1.00      1.00    165972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to LayerModels/lvl1_rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib_file = \"LayerModels/lvl1_rf_model.pkl\"\n",
    "joblib.dump(rf, joblib_file)\n",
    "\n",
    "print(\"Model saved to\", joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 - Neural Network\n",
    "DDos vs PortScan vs WebAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "PortScan        158804\n",
      "DDoS            128025\n",
      "BruteForce       50000\n",
      "XSS              50000\n",
      "SQLInjection     50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_2 = X[y != 'BENIGN']\n",
    "y_2 = y[y != 'BENIGN']\n",
    "\n",
    "target_classes = {\n",
    "    \"BruteForce\": 50000,\n",
    "    \"XSS\": 50000,\n",
    "    \"SQLInjection\": 50000\n",
    "}\n",
    "\n",
    "smote = SMOTE(sampling_strategy=target_classes, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_2, y_2)\n",
    "\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "PortScan     158804\n",
      "WebAttack    150000\n",
      "DDoS         128025\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_resampled = y_resampled.apply(lambda x: 'WebAttack' if \"BruteForce\" in x else x)\n",
    "y_resampled = y_resampled.apply(lambda x: 'WebAttack' if \"XSS\" in x else x)\n",
    "y_resampled = y_resampled.apply(lambda x: 'WebAttack' if \"SQLInjection\" in x else x)\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fwd IAT Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Bwd IAT Total</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>SYN Flag Count</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Packet Length Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>4.368290e+05</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>4.368290e+05</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>436829.000000</td>\n",
       "      <td>4.368290e+05</td>\n",
       "      <td>4.368290e+05</td>\n",
       "      <td>436829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.045557</td>\n",
       "      <td>0.130556</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>0.025899</td>\n",
       "      <td>6.649953e-04</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.021438</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.030363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049423</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>6.551843e-02</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.030363</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.859379e-02</td>\n",
       "      <td>5.213140e-02</td>\n",
       "      <td>0.109927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.111454</td>\n",
       "      <td>0.257076</td>\n",
       "      <td>0.116213</td>\n",
       "      <td>0.124527</td>\n",
       "      <td>1.635867e-02</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.102588</td>\n",
       "      <td>0.123741</td>\n",
       "      <td>0.063134</td>\n",
       "      <td>0.088117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143457</td>\n",
       "      <td>0.170456</td>\n",
       "      <td>1.693511e-01</td>\n",
       "      <td>0.028750</td>\n",
       "      <td>0.088117</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>4.333018e-02</td>\n",
       "      <td>1.428156e-01</td>\n",
       "      <td>0.213111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.999999e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.256749e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.114475e-07</td>\n",
       "      <td>4.250000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>1.250000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.939532e-03</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.515349e-03</td>\n",
       "      <td>4.883150e-03</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.062705</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>3.323061e-06</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.480956e-02</td>\n",
       "      <td>0.020883</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.047102e-02</td>\n",
       "      <td>4.344787e-02</td>\n",
       "      <td>0.094638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fwd IAT Std  Bwd Packet Length Max      Idle Mean  \\\n",
       "count  436829.000000          436829.000000  436829.000000   \n",
       "mean        0.045557               0.130556       0.030554   \n",
       "std         0.111454               0.257076       0.116213   \n",
       "min         0.000000               0.000000       0.000000   \n",
       "25%         0.000000               0.000000       0.000000   \n",
       "50%         0.000022               0.000517       0.000000   \n",
       "75%         0.062705               0.115077       0.000000   \n",
       "max         1.000000               1.000000       1.000000   \n",
       "\n",
       "       Subflow Fwd Packets   Fwd IAT Min    Bwd IAT Max       Idle Min  \\\n",
       "count        436829.000000  4.368290e+05  436829.000000  436829.000000   \n",
       "mean              0.025899  6.649953e-04       0.003844       0.022312   \n",
       "std               0.124527  1.635867e-02       0.014993       0.102588   \n",
       "min               0.000000  0.000000e+00       0.000000       0.000000   \n",
       "25%               0.000000  9.999999e-08       0.000000       0.000000   \n",
       "50%               0.009479  1.250000e-07       0.000000       0.000000   \n",
       "75%               0.014218  3.323061e-06       0.000206       0.000000   \n",
       "max               1.000000  1.000000e+00       1.000000       1.000000   \n",
       "\n",
       "            Idle Std  Bwd IAT Total  Avg Fwd Segment Size  ...    Fwd IAT Max  \\\n",
       "count  436829.000000  436829.000000         436829.000000  ...  436829.000000   \n",
       "mean        0.021438       0.012375              0.030363  ...       0.049423   \n",
       "std         0.123741       0.063134              0.088117  ...       0.143457   \n",
       "min         0.000000       0.000000              0.000000  ...       0.000000   \n",
       "25%         0.000000       0.000000              0.000000  ...       0.000000   \n",
       "50%         0.000000       0.000000              0.002867  ...       0.000025   \n",
       "75%         0.000000       0.000257              0.010034  ...       0.043448   \n",
       "max         1.000000       1.000000              1.000000  ...       1.000000   \n",
       "\n",
       "       URG Flag Count  Flow Duration   Fwd IAT Mean  Fwd Packet Length Mean  \\\n",
       "count   436829.000000   4.368290e+05  436829.000000           436829.000000   \n",
       "mean         0.029952   6.551843e-02       0.011962                0.030363   \n",
       "std          0.170456   1.693511e-01       0.028750                0.088117   \n",
       "min          0.000000   0.000000e+00       0.000000                0.000000   \n",
       "25%          0.000000   4.256749e-07       0.000000                0.000000   \n",
       "50%          0.000000   4.939532e-03       0.000014                0.002867   \n",
       "75%          0.000000   4.480956e-02       0.020883                0.010034   \n",
       "max          1.000000   1.000000e+00       1.000000                1.000000   \n",
       "\n",
       "        Bwd IAT Mean  SYN Flag Count  Flow IAT Mean  Flow IAT Max  \\\n",
       "count  436829.000000   436829.000000   4.368290e+05  4.368290e+05   \n",
       "mean        0.001367        0.000002   1.859379e-02  5.213140e-02   \n",
       "std         0.011874        0.001513   4.333018e-02  1.428156e-01   \n",
       "min         0.000000        0.000000   0.000000e+00  0.000000e+00   \n",
       "25%         0.000000        0.000000   9.114475e-07  4.250000e-07   \n",
       "50%         0.000000        0.000000   1.515349e-03  4.883150e-03   \n",
       "75%         0.000063        0.000000   3.047102e-02  4.344787e-02   \n",
       "max         1.000000        1.000000   1.000000e+00  1.000000e+00   \n",
       "\n",
       "       Packet Length Std  \n",
       "count      436829.000000  \n",
       "mean            0.109927  \n",
       "std             0.213111  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000488  \n",
       "75%             0.094638  \n",
       "max             1.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "X_resampled_scaled = pd.DataFrame(X_resampled_scaled, columns=X_resampled.columns)\n",
    "\n",
    "X_resampled_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(128025), np.int64(1): np.int64(158804), np.int64(2): np.int64(150000)}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_resampled_encoded = label_encoder.fit_transform(y_resampled)\n",
    "unique, counts = np.unique(y_resampled_encoded, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nico/Desktop/UPC/PAE/SentinelX/.venv/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385us/step - accuracy: 0.9749 - loss: 0.1011 - val_accuracy: 0.9994 - val_loss: 0.0049\n",
      "Epoch 2/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 426us/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.9994 - val_loss: 0.0033\n",
      "Epoch 3/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381us/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 0.9995 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379us/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.9996 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.9997 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.9996 - val_loss: 0.0023\n",
      "Epoch 7/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.9997 - val_loss: 0.0024\n",
      "Epoch 8/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372us/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9998 - val_loss: 0.0019\n",
      "Epoch 9/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9998 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9997 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9999 - val_loss: 0.0017\n",
      "Epoch 12/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9998 - val_loss: 0.0018\n",
      "Epoch 13/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9998 - val_loss: 0.0025\n",
      "Epoch 14/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9998 - val_loss: 0.0028\n",
      "Epoch 15/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9998 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 17/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9998 - val_loss: 0.0028\n",
      "Epoch 19/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9998 - val_loss: 0.0028\n",
      "Epoch 20/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9998 - val_loss: 0.0024\n",
      "Epoch 21/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399us/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9996 - val_loss: 0.0029\n",
      "Epoch 22/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379us/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9998 - loss: 9.5354e-04 - val_accuracy: 0.9998 - val_loss: 0.0018\n",
      "Epoch 24/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.9999 - val_loss: 0.0016\n",
      "Epoch 25/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 0.0024\n",
      "Epoch 26/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9999 - val_loss: 0.0026\n",
      "Epoch 27/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9998 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9999 - val_loss: 0.0022\n",
      "Epoch 31/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Epoch 32/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 34/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 373us/step - accuracy: 0.9999 - loss: 7.8413e-04 - val_accuracy: 0.9999 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 36/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Epoch 37/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379us/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 0.0021\n",
      "Epoch 38/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 0.0021\n",
      "Epoch 39/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372us/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 404us/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9999 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0028\n",
      "Epoch 42/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372us/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0028\n",
      "Epoch 43/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9998 - val_loss: 0.0025\n",
      "Epoch 44/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9999 - val_loss: 0.0028\n",
      "Epoch 45/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 372us/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.9999 - val_loss: 0.0024\n",
      "Epoch 46/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9999 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380us/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.9999 - val_loss: 0.0026\n",
      "Epoch 48/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.9999 - val_loss: 0.0023\n",
      "Epoch 49/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379us/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9999 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "\u001b[1m8737/8737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9999 - val_loss: 0.0024\n",
      "\u001b[1m2731/2731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216us/step - accuracy: 0.9999 - loss: 0.0015\n",
      "Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled_scaled, y_resampled_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X_train.shape[1]),  # Primera capa oculta con 128 nodos\n",
    "    Dropout(0.3),  # Dropout para prevenir sobreajuste\n",
    "    Dense(64, activation='relu'),  # Segunda capa oculta con 64 nodos\n",
    "    Dropout(0.3),\n",
    "    Dense(3, activation='softmax')  # Capa de salida para clasificación multiclase (3 clases)\n",
    "])\n",
    "\n",
    "# 6. Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',  # Para problemas multiclase\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train_one_hot, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2731/2731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn_classes = np.argmax(y_pred_nn, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_nn_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print other performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_nn_classes)\n",
    "precision = precision_score(y_test, y_pred_nn_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_nn_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_nn_classes, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DDoS': np.int64(0), 'PortScan': np.int64(1), 'WebAttack': np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to LayerModels/lvl2_nn_model.keras\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib_file = \"LayerModels/lvl2_nn_model.keras\"\n",
    "joblib.dump(model, joblib_file)\n",
    "\n",
    "print(\"Model saved to\", joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 3 - XGBoost\n",
    "\n",
    "BruteForce vs XSS vs SQLInjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['AttackType'].isin(['BENIGN', 'PortScan', 'DDoS'])]\n",
    "\n",
    "X = dataset.drop(columns=['AttackType'])\n",
    "y = dataset['AttackType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttackType\n",
      "BruteForce      50000\n",
      "XSS             50000\n",
      "SQLInjection    50000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_classes = {\n",
    "    \"BruteForce\": 50000,\n",
    "    \"XSS\": 50000,\n",
    "    \"SQLInjection\": 50000\n",
    "}\n",
    "\n",
    "smote = SMOTE(sampling_strategy=target_classes, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fwd IAT Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Fwd IAT Min</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Bwd IAT Total</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>SYN Flag Count</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>Flow IAT Max</th>\n",
       "      <th>Packet Length Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.00000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.155798</td>\n",
       "      <td>0.059209</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.061290</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.176609</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.054995</td>\n",
       "      <td>0.077837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069851</td>\n",
       "      <td>0.08718</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.032521</td>\n",
       "      <td>0.077837</td>\n",
       "      <td>0.090796</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.025139</td>\n",
       "      <td>0.081944</td>\n",
       "      <td>0.107954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.149527</td>\n",
       "      <td>0.112220</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.207489</td>\n",
       "      <td>0.042527</td>\n",
       "      <td>0.364832</td>\n",
       "      <td>0.044088</td>\n",
       "      <td>0.110348</td>\n",
       "      <td>0.176002</td>\n",
       "      <td>0.138325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096107</td>\n",
       "      <td>0.28210</td>\n",
       "      <td>0.136797</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.138325</td>\n",
       "      <td>0.195375</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.054172</td>\n",
       "      <td>0.092227</td>\n",
       "      <td>0.192855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.044456</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.230809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088973</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.045987</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029658</td>\n",
       "      <td>0.088973</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.252117</td>\n",
       "      <td>0.049345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.171732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.050089</td>\n",
       "      <td>0.048615</td>\n",
       "      <td>0.171732</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.150857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fwd IAT Std  Bwd Packet Length Max      Idle Mean  \\\n",
       "count  150000.000000          150000.000000  150000.000000   \n",
       "mean        0.155798               0.059209       0.006451   \n",
       "std         0.149527               0.112220       0.059051   \n",
       "min         0.000000               0.000000       0.000000   \n",
       "25%         0.000695               0.000000       0.000000   \n",
       "50%         0.230809               0.000000       0.000000   \n",
       "75%         0.252117               0.049345       0.000000   \n",
       "max         1.000000               1.000000       1.000000   \n",
       "\n",
       "       Subflow Fwd Packets    Fwd IAT Min    Bwd IAT Max       Idle Min  \\\n",
       "count        150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean              0.061290       0.002643       0.176609       0.003336   \n",
       "std               0.207489       0.042527       0.364832       0.044088   \n",
       "min               0.000000       0.000000       0.000000       0.000000   \n",
       "25%               0.009479       0.000005       0.000000       0.000000   \n",
       "50%               0.009479       0.000013       0.000000       0.000000   \n",
       "75%               0.014218       0.000016       0.000814       0.000000   \n",
       "max               1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "            Idle Std  Bwd IAT Total  Avg Fwd Segment Size  ...    Fwd IAT Max  \\\n",
       "count  150000.000000  150000.000000         150000.000000  ...  150000.000000   \n",
       "mean        0.012381       0.054995              0.077837  ...       0.069851   \n",
       "std         0.110348       0.176002              0.138325  ...       0.096107   \n",
       "min         0.000000       0.000000              0.000000  ...       0.000000   \n",
       "25%         0.000000       0.000000              0.000000  ...       0.000429   \n",
       "50%         0.000000       0.000000              0.000000  ...       0.088973   \n",
       "75%         0.000000       0.000084              0.171732  ...       0.097216   \n",
       "max         1.000000       1.000000              1.000000  ...       1.000000   \n",
       "\n",
       "       URG Flag Count  Flow Duration   Fwd IAT Mean  Fwd Packet Length Mean  \\\n",
       "count    150000.00000  150000.000000  150000.000000           150000.000000   \n",
       "mean          0.08718       0.073689       0.032521                0.077837   \n",
       "std           0.28210       0.136797       0.056343                0.138325   \n",
       "min           0.00000       0.000000       0.000000                0.000000   \n",
       "25%           0.00000       0.044456       0.000146                0.000000   \n",
       "50%           0.00000       0.045987       0.044487                0.000000   \n",
       "75%           0.00000       0.050089       0.048615                0.171732   \n",
       "max           1.00000       1.000000       1.000000                1.000000   \n",
       "\n",
       "        Bwd IAT Mean  SYN Flag Count  Flow IAT Mean   Flow IAT Max  \\\n",
       "count  150000.000000   150000.000000  150000.000000  150000.000000   \n",
       "mean        0.090796        0.000007       0.025139       0.081944   \n",
       "std         0.195375        0.002582       0.054172       0.092227   \n",
       "min         0.000000        0.000000       0.000000       0.000000   \n",
       "25%         0.000000        0.000000       0.004806       0.064768   \n",
       "50%         0.000000        0.000000       0.029658       0.088973   \n",
       "75%         0.000889        0.000000       0.032410       0.097216   \n",
       "max         1.000000        1.000000       1.000000       1.000000   \n",
       "\n",
       "       Packet Length Std  \n",
       "count      150000.000000  \n",
       "mean            0.107954  \n",
       "std             0.192855  \n",
       "min             0.000000  \n",
       "25%             0.000000  \n",
       "50%             0.000000  \n",
       "75%             0.150857  \n",
       "max             1.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "X_resampled_scaled = pd.DataFrame(X_resampled_scaled, columns=X_resampled.columns)\n",
    "\n",
    "X_resampled_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.int64(50000), np.int64(1): np.int64(50000), np.int64(2): np.int64(50000)}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_resampled_encoded = label_encoder.fit_transform(y_resampled)\n",
    "unique, counts = np.unique(y_resampled_encoded, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      9938\n",
      "           1       0.98      0.99      0.99     10110\n",
      "           2       0.98      0.98      0.98      9952\n",
      "\n",
      "    accuracy                           0.98     30000\n",
      "   macro avg       0.98      0.98      0.98     30000\n",
      "weighted avg       0.98      0.98      0.98     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled_scaled, y_resampled_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    colsample_bytree=1.0,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=9,\n",
    "    n_estimators=200,\n",
    "    subsample=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BruteForce': np.int64(0), 'SQLInjection': np.int64(1), 'XSS': np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to LayerModels/lvl3_xgboost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib_file = \"LayerModels/lvl3_xgboost_model.pkl\"\n",
    "joblib.dump(xgb_model, joblib_file)\n",
    "\n",
    "print(f\"Model saved to {joblib_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
